# D√©pannage et r√©solution de probl√®mes

## Table des mati√®res

1. [Probl√®mes de m√©moire GPU](#probl√®mes-de-m√©moire-gpu)
2. [Pages qui timeout](#pages-qui-timeout)
3. [Traitement interrompu](#traitement-interrompu)
4. [Erreurs de mod√®le](#erreurs-de-mod√®le)
5. [Probl√®mes de performance](#probl√®mes-de-performance)
6. [Logs et monitoring](#logs-et-monitoring)
7. [D√©ploiement en production](#d√©ploiement-en-production)

---

## Probl√®mes de m√©moire GPU

### Sympt√¥me : OutOfMemoryError (OOM)

```
RuntimeError: CUDA out of memory. Tried to allocate X MiB
```

### Solutions

#### Solution 1 : R√©duire le DPI

```bash
cd src
python3 ocr_nanonets_pausable.py --dpi 100
```

Impact :
- ‚úÖ R√©duit la m√©moire de ~40%
- ‚úÖ Traitement plus rapide
- ‚ö†Ô∏è Qualit√© OCR peut l√©g√®rement diminuer

DPI recommand√©s :
- **150** : Qualit√© optimale (d√©faut)
- **120** : Bon compromis
- **100** : √âconomie maximale
- **80** : Derni√®re option (texte petit)

#### Solution 2 : Utiliser CPU offload

```bash
cd bin
./run_full_ocr.sh  # Utilise la variante cpu_offload
```

Ou manuellement :
```bash
cd src
python3 ocr_nanonets_cpu_offload.py
```

**Comment √ßa marche** :
- D√©charge certaines parties du mod√®le vers la RAM
- Plus lent (~30% plus lent)
- Tr√®s stable m√™me avec 6GB VRAM

#### Solution 3 : Fermer les applications GPU

```bash
# V√©rifier les processus utilisant le GPU
nvidia-smi

# Tuer un processus sp√©cifique
kill -9 [PID]
```

Applications √† fermer :
- Navigateurs (Chrome, Firefox)
- Autres mod√®les ML
- Jeux
- Compositeurs graphiques intensifs

#### Solution 4 : Nettoyer le cache

```bash
cd src
python3 -c "import torch; torch.cuda.empty_cache(); print('Cache cleared')"
```

### Sympt√¥me : Ralentissement progressif

Le traitement ralentit au fil du temps.

**Cause** : Accumulation de cache m√©moire

**Solution** : Red√©marrer p√©riodiquement
```bash
# Arr√™ter proprement
Ctrl+C

# Relancer (reprise auto)
cd bin
./START_OCR.sh
```

Le script reprend automatiquement l√† o√π il s'est arr√™t√©.

---

## Pages qui timeout

### Sympt√¥me : Pages ignor√©es

```
‚ö†Ô∏è TIMEOUT page 23 apr√®s 120 secondes
‚Üí Page ignor√©e, passage √† la suivante
```

### Comprendre les timeouts

**Pourquoi ?**
- Pages tr√®s complexes (tableaux, images)
- Texte manuscrit difficile
- Qualit√© PDF faible
- Charge GPU √©lev√©e

**Impact** :
- Page ignor√©e = pas de texte extrait
- Traitement continue avec la page suivante
- Inform√© dans `_summary.json`

### Compter les pages timeout

```bash
cd src
python3 count_aborted_pages.py
```

**Sortie** :
```
üìÅ Total de PDFs trait√©s: 42
‚ö†Ô∏è  PDFs avec pages avort√©es: 5
‚ùå Total de pages avort√©es: 12
```

### Retraiter avec timeout √©tendu

```bash
cd src
python3 retry_aborted_pages.py
```

**Param√®tres du retry** :
- Timeout : **300 secondes** (5 minutes vs 2 minutes)
- Ordre : PDFs avec le moins d'√©checs d'abord
- Mise √† jour : Met √† jour les .md et _summary.json automatiquement

**Surveiller le retry** :
```bash
cd bin
./monitor_retry.sh
```

### Ajuster le timeout d√®s le d√©part

Si vous savez que les PDFs sont complexes :

```bash
cd src
python3 ocr_nanonets_pausable.py --ocr-timeout 300
```

**Compromis** :
- ‚è±Ô∏è Traitement plus long
- ‚úÖ Moins de pages ignor√©es

---

## Traitement interrompu

### Interruption volontaire (Ctrl+C)

**Statut** : ‚úÖ Normal, g√©r√© automatiquement

**Pour reprendre** :
```bash
cd bin
./START_OCR.sh  # Reprend automatiquement
```

ou

```bash
./run_resume.sh  # Script d√©di√©
```

### Interruption syst√®me (crash, coupure)

**Statut** : ‚úÖ G√©r√© par la reprise automatique

**Ce qui est pr√©serv√©** :
- PDFs compl√®tement trait√©s (avec `_summary.json`)
- Pages d√©j√† trait√©es dans un PDF incomplet

**Ce qui est perdu** :
- Page en cours de traitement (sera retrait√©e)

**Pour reprendre** :
```bash
cd bin
./START_OCR.sh
```

### V√©rifier l'√©tat apr√®s interruption

```bash
cd src

# Voir combien de PDFs trait√©s
ls ../data/output/ocr_results/ | wc -l

# V√©rifier les pages timeout
python3 count_aborted_pages.py
```

### Supprimer un PDF incomplet (optionnel)

Si un PDF semble corrompu :

```bash
# Identifier le PDF probl√©matique
cd data/output/ocr_results/
ls -lt  # Trier par date

# Supprimer le dossier
rm -rf R1049-13C-XXXXX-23516/

# Relancer (retraitera ce PDF)
cd ../../bin
./START_OCR.sh
```

---

## Erreurs de mod√®le

### Erreur : Mod√®le non trouv√©

```
OSError: nanonets/Nanonets-OCR2-3B is not a local folder and is not a valid model identifier
```

**Cause** : Premi√®re utilisation, mod√®le pas encore t√©l√©charg√©

**Solution** : V√©rifier la connexion internet
```bash
# Le mod√®le (~6GB) sera t√©l√©charg√© automatiquement
cd src
python3 ocr_nanonets_pausable.py --single-pdf "../data/input/[un_pdf].pdf"
```

**T√©l√©chargement manuel** (si √©chec) :
```bash
python3 -c "from transformers import AutoModelForImageTextToText; \
AutoModelForImageTextToText.from_pretrained('nanonets/Nanonets-OCR2-3B', trust_remote_code=True)"
```

### Erreur : CUDA non disponible

```
AssertionError: CUDA is not available
```

**V√©rifications** :
```bash
# 1. V√©rifier CUDA
nvidia-smi

# 2. V√©rifier PyTorch
python3 -c "import torch; print(torch.cuda.is_available())"
```

**Si False** :
```bash
# R√©installer PyTorch avec support CUDA
pip install torch torchvision --index-url https://download.pytorch.org/whl/cu118
```

---

## Probl√®mes de performance

### Traitement tr√®s lent

**Sympt√¥mes** :
- Plus de 60 minutes par PDF
- GPU usage < 50%

**Diagnostics** :

```bash
# V√©rifier GPU
nvidia-smi

# V√©rifier si CPU offload est utilis√©
ps aux | grep ocr_nanonets
```

**Solutions** :

1. **V√©rifier le script utilis√©**
```bash
# Rapide (recommand√©)
python3 ocr_nanonets_pausable.py

# Lent (CPU offload)
python3 ocr_nanonets_cpu_offload.py
```

2. **Augmenter le DPI peut aider**
```bash
# Si GPU sous-utilis√©, augmenter DPI
python3 ocr_nanonets_pausable.py --dpi 180
```

3. **V√©rifier thermal throttling**
```bash
nvidia-smi --query-gpu=temperature.gpu --format=csv

# Si > 80¬∞C, am√©liorer le refroidissement
```

### PDF tr√®s long (>200 pages)

**Probl√®me** : Risque de timeout global

**Solution** : Traiter par batch manuel
```bash
# Diviser le PDF en plusieurs fichiers
# Puis traiter s√©par√©ment

cd src
python3 ocr_nanonets_pausable.py --single-pdf "../data/input/part1.pdf"
python3 ocr_nanonets_pausable.py --single-pdf "../data/input/part2.pdf"
```

---

## Logs et monitoring

### Localisation des logs

```
logs/
‚îú‚îÄ‚îÄ ocr_processing.log    # Traitement g√©n√©ral
‚îú‚îÄ‚îÄ ocr_production.log    # Production (START_OCR.sh)
‚îî‚îÄ‚îÄ retry_aborted.log     # Retraitement
```

### Voir les logs en temps r√©el

```bash
# Logs principaux
tail -f logs/ocr_production.log

# Filtrer les erreurs
tail -f logs/ocr_production.log | grep -i error

# Filtrer les timeouts
tail -f logs/ocr_production.log | grep -i timeout
```

### Dashboard de monitoring

```bash
cd bin
./monitor_ocr.sh
```

**Affiche** :
- Progression globale (PDFs trait√©s/total)
- PDF en cours + page actuelle
- Usage GPU en temps r√©el
- Erreurs et timeouts
- Taille des r√©sultats
- Estimation temps restant

**Rafra√Æchissement** : Toutes les 5 secondes

### Logs personnalis√©s

Rediriger vers un fichier sp√©cifique :

```bash
cd src
python3 ocr_nanonets_pausable.py 2>&1 | tee ../logs/custom_run.log
```

### Analyser les logs

**Compter les erreurs** :
```bash
grep -c "ERROR" logs/ocr_production.log
```

**Compter les timeouts** :
```bash
grep -c "TIMEOUT" logs/ocr_production.log
```

**Voir les derni√®res erreurs** :
```bash
grep "ERROR" logs/ocr_production.log | tail -20
```

**Extraire les pages timeout** :
```bash
grep "TIMEOUT" logs/ocr_production.log | grep "page"
```

---

## D√©ploiement en production

### Configuration recommand√©e

**Mat√©riel** :
- GPU : NVIDIA 8GB+ VRAM (RTX 3060, RTX 4060, etc.)
- RAM : 16GB minimum
- Stockage : SSD pour meilleure performance I/O
- Refroidissement : Bon syst√®me de ventilation

**Logiciel** :
- OS : Linux (Ubuntu 20.04+, Fedora 38+)
- Python : 3.10+
- CUDA : 11.8 ou 12.1
- Drivers : Derni√®re version NVIDIA

### Lancement en production

#### Option 1 : Screen session

```bash
# Cr√©er une session screen
screen -S ocr_production

# Dans la session
cd /path/to/nanosetTests/bin
./START_OCR.sh

# D√©tacher : Ctrl+A puis D
# Rattacher plus tard : screen -r ocr_production
```

#### Option 2 : Tmux

```bash
# Cr√©er session tmux
tmux new -s ocr_production

# Dans la session
cd /path/to/nanosetTests/bin
./START_OCR.sh

# D√©tacher : Ctrl+B puis D
# Rattacher : tmux attach -t ocr_production
```

#### Option 3 : Service systemd

Cr√©er `/etc/systemd/system/ocr-nanonets.service` :

```ini
[Unit]
Description=OCR Nanonets Processing
After=network.target

[Service]
Type=simple
User=steeven
WorkingDirectory=/home/steeven/PycharmProjects/nanosetTests/bin
ExecStart=/home/steeven/PycharmProjects/nanosetTests/bin/START_OCR.sh
Restart=on-failure
RestartSec=10

[Install]
WantedBy=multi-user.target
```

Puis :
```bash
sudo systemctl daemon-reload
sudo systemctl start ocr-nanonets
sudo systemctl enable ocr-nanonets  # D√©marrage auto

# V√©rifier
sudo systemctl status ocr-nanonets

# Logs
sudo journalctl -u ocr-nanonets -f
```

### Surveillance en production

#### Monitoring GPU

```bash
# Dashboard GPU temps r√©el
watch -n 1 nvidia-smi

# Ou avec monitoring d√©di√©
cd bin
./monitor_ocr.sh
```

#### Alertes par email (optionnel)

Script de surveillance avec alerte :

```bash
#!/bin/bash
# monitor_with_alert.sh

while true; do
  # V√©rifier si le processus tourne
  if ! pgrep -f "ocr_nanonets_pausable.py" > /dev/null; then
    echo "OCR process stopped!" | mail -s "OCR Alert" user@example.com
    break
  fi

  # V√©rifier GPU
  gpu_usage=$(nvidia-smi --query-gpu=utilization.gpu --format=csv,noheader,nounits)
  if [ "$gpu_usage" -lt 10 ]; then
    echo "GPU usage low: $gpu_usage%" | mail -s "OCR Alert" user@example.com
  fi

  sleep 300  # V√©rifier toutes les 5 minutes
done
```

### Rotation des logs

Pour √©viter les logs trop gros :

```bash
# Cr√©er /etc/logrotate.d/ocr-nanonets
/home/steeven/PycharmProjects/nanosetTests/logs/*.log {
    daily
    rotate 7
    compress
    delaycompress
    missingok
    notifempty
}
```

### Sauvegarde automatique

```bash
#!/bin/bash
# backup_results.sh

DATE=$(date +%Y%m%d)
SOURCE="/home/steeven/PycharmProjects/nanosetTests/data/output/ocr_results"
DEST="/backup/ocr_results_$DATE"

rsync -av --progress "$SOURCE" "$DEST"
echo "Backup completed: $DEST"
```

Ajouter dans crontab :
```bash
crontab -e

# Sauvegarde quotidienne √† 2h du matin
0 2 * * * /path/to/backup_results.sh
```

### Performance tuning

#### 1. Optimiser I/O disque

```bash
# Utiliser tmpfs pour fichiers temporaires (si RAM disponible)
sudo mount -t tmpfs -o size=4G tmpfs /tmp/ocr_temp

# Modifier le script pour utiliser ce dossier
export TMPDIR=/tmp/ocr_temp
```

#### 2. Nice priority

```bash
# R√©duire la priorit√© CPU si besoin
nice -n 10 ./START_OCR.sh
```

#### 3. GPU power limit

```bash
# Augmenter la limite de puissance (si support√©)
sudo nvidia-smi -pl 250  # 250W

# V√©rifier
nvidia-smi -q -d POWER
```

### Checklist de d√©ploiement

- [ ] Environnement Python configur√©
- [ ] Mod√®le t√©l√©charg√© (`~6GB`)
- [ ] Logs configur√©s avec rotation
- [ ] Monitoring en place
- [ ] Session persistante (screen/tmux/systemd)
- [ ] Sauvegarde automatique configur√©e
- [ ] Test sur un PDF valid√©
- [ ] Documentation accessible √† l'√©quipe

---

## FAQ - Questions fr√©quentes

### Combien de temps pour traiter 42 PDFs ?

**Estimation** : 24-32 heures

**D√©tail** :
- PDF simple (20 pages) : ~15-20 min
- PDF moyen (50 pages) : ~35-45 min
- PDF complexe (100 pages) : ~60-90 min

**Facteurs** :
- Complexit√© du texte
- Qualit√© du PDF
- DPI utilis√©
- Charge GPU

### Puis-je traiter plusieurs PDFs en parall√®le ?

**Non recommand√©** avec 8GB VRAM.

**Raison** : Le mod√®le consomme ~6-7GB seul.

**Alternative** : Si vous avez 2 GPUs :
```bash
# GPU 0
CUDA_VISIBLE_DEVICES=0 python3 ocr_nanonets_pausable.py --input-dir batch1/

# GPU 1
CUDA_VISIBLE_DEVICES=1 python3 ocr_nanonets_pausable.py --input-dir batch2/
```

### Les r√©sultats sont-ils d√©terministes ?

**Oui**, le m√™me PDF donnera le m√™me r√©sultat.

**Sauf** :
- Si le mod√®le est mis √† jour
- Si les param√®tres changent (DPI, etc.)

### Puis-je modifier les patterns de d√©tection de documents ?

**Oui**, dans `src/ocr_nanonets_pausable.py` :

```python
def detect_document_boundary(self, text: str, page_num: int) -> bool:
    # Modifier ces patterns
    date_pattern = r'\d{2}/\d{2}/\d{4}'
    reference_pattern = r'R\d{4}-13C-'
    # ...
```

### Comment exporter en JSON au lieu de Markdown ?

Modifier la fonction `save_document()` dans le script Python, ou utiliser un script de conversion :

```bash
# Exemple : Convertir tous les .md en .json
for dir in data/output/ocr_results/*/; do
  # Script de conversion personnalis√©
  python3 convert_md_to_json.py "$dir"
done
```

---

**Besoin d'aide ?** Consultez `GUIDE_PROJET.md` pour plus de d√©tails sur le fonctionnement interne.
